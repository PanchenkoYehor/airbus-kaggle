{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code]\n%pip install tensorflow\n%pip install patchify\n%pip install segmentation-models\n\n%env SM_FRAMEWORK=tf.keras\nimport segmentation_models as sm\nimport tensorflow as tf\nimport keras\nimport albumentations as A\nimport torch\nimport csv\nfrom torch import nn\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nimport random\nfrom random import randrange, shuffle\nfrom matplotlib import pyplot as plt\nimport matplotlib.patches as patches\nfrom torchvision import transforms\nfrom torchvision.transforms.functional import rotate\nimport torchvision\nimport cv2\nimport time, glob\nimport PIL\nimport pandas as pd \nimport torch.utils.data as data\nimport csv\nimport glob\nimport os\nfrom sklearn.model_selection import train_test_split\nimport pickle\nfrom tqdm.notebook import tqdm\nfrom PIL import Image\nfrom patchify import patchify, unpatchify\n\n\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\nROOT_DIR = \"../input/airbus-ship-detection\"\ntest_folder = os.path.join(ROOT_DIR, 'test_v2')\ntrain_folder = os.path.join(ROOT_DIR, 'train_v2')\n\ndef rle_to_pixels(rle_code):\n    '''\n    Transforms a RLE code string into a list of pixels of a (768, 768) canvas\n    '''\n    rle_code = [int(i) for i in rle_code.split()]\n    pixels = [(pixel_position % 768, pixel_position // 768) \n                 for start, length in list(zip(rle_code[0:-1:2], rle_code[1::2])) \n                 for pixel_position in range(start, start + length)]\n    return pixels\n\n\ndef get_preprocessing(preprocessing_fn):\n    _transform = [\n        A.Lambda(image=preprocessing_fn),\n    ]\n    return A.Compose(_transform)\n\nclass Dataloder(keras.utils.Sequence):\n    def __init__(self, dataset, batch_size=1, shuffle=False):\n        self.dataset = dataset\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.indexes = np.arange(len(dataset))\n\n        self.on_epoch_end()\n\n    def __getitem__(self, i):    \n        start = i * self.batch_size\n        stop = (i + 1) * self.batch_size\n        data = []\n        for j in range(start, stop):\n            data.append(self.dataset[j])\n        \n        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n        return batch\n    \n    def __len__(self):\n        return len(self.indexes) // self.batch_size\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            self.indexes = np.random.permutation(self.indexes)\n            \n\n\nclass TestDataset():\n    \n    def __init__(self, root_paths, paths, preprocessing_fn=None, split_into_squares=False, limit=None):\n        self.root_paths = root_paths\n        self.paths = paths[:limit] if split_into_squares == False else [(x,i,j) for x in paths[:limit] for i in range(6) for j in range(6)] \n        self.preprocessing_fn = preprocessing_fn\n       \n    def __len__(self):\n        return len(self.paths)\n    \n    def getranditem(self):\n        ImageId, qi, qj = self.paths[randrange(self.__len__())]\n         \n        img_path = f\"{ROOT_DIR}/{self.root_paths}/{ImageId}\"\n        image = cv2.imread(img_path)\n\n        step = 128\n        patch_img = patchify(image, (step,step, 3), step=step)\n        return patch_img[qi][qj][0], (ImageId, qi, qj)\n    \n    def __getitem__(self, idx):\n        ImageId, qi, qj = self.paths[idx]\n\n        img_path = f\"{ROOT_DIR}/{self.root_paths}/{ImageId}\"\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n        \n        step = 128\n        patch_img = patchify(image, (step,step, 3), step=step)\n        image = patch_img[qi][qj][0]                \n        \n        if self.preprocessing_fn is not None:\n            image = np.array(image)\n            sample = self.preprocessing_fn(image = image)\n            image = sample['image']\n        \n        image = image.astype(np.float32)\n        tf.cast(image, tf.float32)\n        return image, (ImageId, qi, qj)\n    \n\ndef make_up_prediction(predictions):\n    num_images = predictions.shape[0] // 36\n    images_batch = predictions.squeeze().reshape((num_images, 36,128,128))\n    result = []\n#     print(images_batch.shape)\n    for batch in images_batch:\n#         print(batch.shape)\n        img = unpatchify(batch.reshape(6, 6, 128, 128), (768, 768))\n        threshold = 0.5\n        img[img >= threshold] = 1\n        img[img < threshold] = 0\n        result.append(img)\n    return result\n\n\nif __name__ == \"__main__\":\n    limit = 10 # how much images infer\n    mask_to_one = True # if True than mask is [0,1] otherwise [0, 255]\n    output_dir = \"/kaggle/working/output\" # folder where to store mask images\n    batch_size = 36 # batch size for prediction, please make it divisible by 36\n    model_path = \"/kaggle/input/airbus-models/best_model (2)_maybe_best.h5\" # model path to load model from\n    \n    preprocess_input = sm.get_preprocessing(BACKBONE)    \n    model.load_weights(model_path)\n    \n    testAirbusShipDataset = TestDataset(\"test_v2\",\n                                    os.listdir(test_folder), \n                                    preprocessing_fn=get_preprocessing(preprocess_input),\n                                    split_into_squares = True,\n                                    limit=limit\n                                    )\n    test_dataloader = Dataloder(testAirbusShipDataset, batch_size=batch_size, shuffle=False)\n    predictions = model.predict(test_dataloader)\n    maked_up = make_up_prediction(predictions)\n    print(f'Predictions contains {len(maked_up)} images each has size {maked_up[0].shape}')\n    \n    if not os. path. isdir(output_dir):\n        os.mkdir(output_dir)\n    for i, filename in tqdm(enumerate(os.listdir(test_folder)[:limit])):\n        im = Image.fromarray(maked_up[i] * (1. if mask_to_one else 255.))\n        if im.mode != 'RGB':\n            im = im.convert('RGB')\n        im.save(os.path.join(output_dir, filename))\n","metadata":{"_uuid":"fec62bcd-bc02-45fd-ba01-6376e1a1cc7d","_cell_guid":"67914db2-6fc2-4671-980f-49c45119dd9e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}